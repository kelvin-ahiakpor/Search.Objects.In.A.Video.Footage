{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce74f137",
   "metadata": {
    "id": "ce74f137"
   },
   "source": [
    "# Assignment 4: Search Objects In A Video Footage - kelvin.ahiakpor & emmanuel.acquaye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a765bda",
   "metadata": {
    "id": "1a765bda"
   },
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02dd80",
   "metadata": {
    "id": "de02dd80"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98140eae",
   "metadata": {
    "id": "98140eae"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import display, clear_output, Javascript\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input,decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001aed4",
   "metadata": {
    "id": "0001aed4"
   },
   "source": [
    "### Setting job timeout for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42967b9",
   "metadata": {
    "id": "b42967b9"
   },
   "outputs": [],
   "source": [
    "os.environ['JOBLIB_START_METHOD'] = 'loky'\n",
    "os.environ['JOBLIB_TIMEOUT'] = '300'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93fb20",
   "metadata": {},
   "source": [
    "### Custom recipes for DataFrame inspection\n",
    "Object predictions will be stored in a dataframe so it can be displayed in a friendly manner in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288fa4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.precision', 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82755f5-c6f8-4d0b-8cef-accc84a91e84",
   "metadata": {
    "id": "d82755f5-c6f8-4d0b-8cef-accc84a91e84"
   },
   "source": [
    "# Task 1\n",
    "Use a pretrained Google Inception V3 deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76355000",
   "metadata": {},
   "source": [
    "Downloading the pretrained weights from the ImageNet dataset which for our image classifcation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1bc8ec7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1bc8ec7",
    "outputId": "6033a481-938b-431d-8248-5d15e7e03c78"
   },
   "outputs": [],
   "source": [
    "model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496dff0",
   "metadata": {
    "id": "95bcbf81-3ff1-4947-abe6-89008fb8e5f4"
   },
   "source": [
    "**Defining a function to preprocess images for InceptionV3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95bcbf81-3ff1-4947-abe6-89008fb8e5f4",
   "metadata": {
    "id": "95bcbf81-3ff1-4947-abe6-89008fb8e5f4"
   },
   "outputs": [],
   "source": [
    "def preprocess_frame(frame_path):\n",
    "    img = image.load_img(frame_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83732ad9",
   "metadata": {
    "id": "95bcbf81-3ff1-4947-abe6-89008fb8e5f4"
   },
   "source": [
    "**Defining a function to get top 5 predictions for each frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef56a797-67fa-4702-9c63-2b3d15327d5f",
   "metadata": {
    "id": "ef56a797-67fa-4702-9c63-2b3d15327d5f"
   },
   "outputs": [],
   "source": [
    "def get_predictions(frame_path):\n",
    "    x = preprocess_frame(frame_path)\n",
    "    preds = model.predict(x)\n",
    "    return decode_predictions(preds, top=5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acb5e3",
   "metadata": {
    "id": "13996d20-5eac-4ed8-a2f7-a3cff5e103e9"
   },
   "source": [
    "## Task 2 \n",
    "Ensure the implementation is general enough to accept any user-provided video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a690f4d",
   "metadata": {},
   "source": [
    "**Accepting all video formats**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557886a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_formats = 'video/*'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de6af7",
   "metadata": {
    "id": "13996d20-5eac-4ed8-a2f7-a3cff5e103e9"
   },
   "source": [
    "## Task 3\n",
    "Allow users to upload videos through Colab or any other method  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13996d20-5eac-4ed8-a2f7-a3cff5e103e9",
   "metadata": {
    "id": "13996d20-5eac-4ed8-a2f7-a3cff5e103e9"
   },
   "source": [
    "Here we define **3** sets of functions to allow uploads whether this notebook is run in Colab or Jupyter  \n",
    "**1** The first takes user input and runs the desired upload method  \n",
    "**2** The second set of functions handles uploads from Google Colab  \n",
    "**3** The third set handles uploads from Jupyter   \n",
    "\n",
    "Eventually we deploy in Streamlit where we can have even more upload generalization capabilities  \n",
    "**Note:** The technique used is handling imports in the function to dynamically import modules based on dependencies determined by runtime conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709e2cf",
   "metadata": {},
   "source": [
    "**Setting a video size threshold of 100MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfac45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_size_threshold = 100 * 1024 * 1024  # 100 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff335571",
   "metadata": {},
   "source": [
    "**Global variables**  \n",
    "Dictionary of upload information   \n",
    "Video path  \n",
    "Upload Widget\n",
    "Upload Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0904f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_info = None\n",
    "video_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa33aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_widget = widgets.FileUpload(accept=accepted_formats, multiple=False)\n",
    "upload_button = widgets.Button(description=\"Process Upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2f3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_completed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc32907",
   "metadata": {},
   "source": [
    "**Function Set 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21c1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_run_choice():\n",
    "    global video_path\n",
    "    while True:\n",
    "        choice = input(\"Enter '1' for Google Colab upload or '2' for Jupyter upload.\" + \n",
    "                       \" 2 is recommended however as it works across platforms : \")\n",
    "        if choice == '1':\n",
    "            clear_output(wait=False)\n",
    "            video_path = upload_files_colab()  # Make sure video_path is updated\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            clear_output(wait=False)\n",
    "            show_upload_widget() \n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter '1' or '2'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5f64a",
   "metadata": {},
   "source": [
    "**Function Set 2 (Google Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1182c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_file_upload_colab(uploaded_files, memory_size_threshold):\n",
    "    global video_path\n",
    "    for filename in uploaded_files.keys():\n",
    "        file_size = len(uploaded_files[filename])\n",
    "        if file_size > memory_size_threshold:\n",
    "            print(f'The file \"{filename}\" exceeds the memory size threshold of {memory_size_threshold / (1024 * 1024)} MB.')\n",
    "            return None\n",
    "        else:\n",
    "            video_path = list(uploaded.keys())[0]\n",
    "            print(f'User uploaded file \"{filename}\" with size {file_size} bytes')\n",
    "            #save_file_colab(filename, uploaded_files[filename])\n",
    "            return filename  # Return the filename for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1301b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_colab():\n",
    "    from google.colab import files  # Import inside the function to avoid platform crash\n",
    "    uploaded = files.upload()\n",
    "    filename = handle_file_upload_colab(uploaded, memory_size_threshold)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03b03b",
   "metadata": {},
   "source": [
    "**Function Set 3 (Jupyter)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "336e355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_file_upload(uploaded_files, memory_size_threshold):\n",
    "    for filename, file_info in uploaded_files.items():\n",
    "        file_size = file_info['metadata']['size']\n",
    "        if file_size > memory_size_threshold:\n",
    "            print(f'The file \"{filename}\" exceeds the memory size threshold of {memory_size_threshold / (1024 * 1024)} MB.')\n",
    "            return None  # Indicates that the file is too large\n",
    "        else:\n",
    "            print(f'User uploaded file \"{filename}\" with size {file_size} bytes')\n",
    "            save_file_jupyter(filename, file_info['content'])\n",
    "            return filename  # Indicates that the file is within the limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97cf6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_jupyter(filename, file_content):\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(file_content)\n",
    "    print(f'File \"{filename}\" has been saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2809a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(button):\n",
    "    global upload_completed\n",
    "    global video_path\n",
    "    clear_output(wait=False)\n",
    "    uploaded_files = upload_widget.value\n",
    "    # Handle file validation and save\n",
    "    video_path = validate_file_upload(uploaded_files, memory_size_threshold)\n",
    "    if video_path:\n",
    "        print(f\"Video path set to: {video_path}\")\n",
    "        upload_completed = True  # Mark the upload as complete\n",
    "    else:\n",
    "        print(\"No valid video file uploaded.\")\n",
    "    \n",
    "    if upload_completed:\n",
    "        print()\n",
    "        print(\"Upload complete. You can now proceed to the run the next cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ca01342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_upload_widget():\n",
    "    global upload_button\n",
    "    upload_button = widgets.Button(description=\"Upload Video\")\n",
    "    upload_button.on_click(process_files)\n",
    "    \n",
    "    # Display the widgets\n",
    "    display(upload_widget)\n",
    "    display(upload_button)\n",
    "    \n",
    "    print(\"Please upload a file and then click the 'Upload Video' button.\")\n",
    "    wait_for_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "838be7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_video():\n",
    "    print(\"Waiting for file upload...\")\n",
    "    print(\"You have 15 seconds to upload your video\")\n",
    "    print(\"If you have already uploaded and clicked 'Upload Video' please be patient.\")\n",
    "    print()\n",
    "    count = 1\n",
    "    while not upload_completed:\n",
    "        time.sleep(3)  # Check every 5 seconds\n",
    "        print(f\"{15 - (count*3)} seconds left...\")\n",
    "        count+=1\n",
    "        if count == 5:\n",
    "            raiseBreak()\n",
    "    if video_path:\n",
    "        print(\"File upload detected. Proceeding with processing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb97a",
   "metadata": {},
   "source": [
    "**Video upload happens here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc199a",
   "metadata": {},
   "source": [
    "A threading mechanism to wait for input, stop and let user manually continue cell execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb6578b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoUploadBreak(Exception):\n",
    "    def __init__(self, message=\"\"\"The program has halted here to take video,  \n",
    "    No video detected yet.\n",
    "    Did you click 'Upload Video'?\n",
    "    You can still go ahead even though the given time elapsed\n",
    "    If you're using Jupyter, clicking the button should fix the issue.\n",
    "    If you're using Google Colab, run this cell again after clicking the button`\"\"\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4246cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raiseBreak():\n",
    "    raise VideoUploadBreak()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466f342",
   "metadata": {},
   "source": [
    "Now we can allow user to upload video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0400b",
   "metadata": {},
   "source": [
    "**Allowing user to upload video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15cac70c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User uploaded file \"truck.MOV\" with size 8881893 bytes\n",
      "File \"truck.MOV\" has been saved.\n",
      "Video path set to: truck.MOV\n",
      "\n",
      "Upload complete. You can now proceed to the run the next cells.\n"
     ]
    }
   ],
   "source": [
    "select_run_choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3004b6-ab40-4d0d-8f08-ff64374c2248",
   "metadata": {
    "id": "0e3004b6-ab40-4d0d-8f08-ff64374c2248"
   },
   "source": [
    "## Task 4\n",
    "Split the uploaded video into frames and feed the frames into the Google Inception V3 model to detect objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4dbaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1419d2cb-a9f6-4ad8-a219-0fcbe212f4db",
    "outputId": "943ef33e-3750-413c-cd7b-4a0ab22260cf"
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    success, image = vidcap.read()\n",
    "    while success:\n",
    "        frame_path = os.path.join(output_folder, f\"frame{count}.jpg\")\n",
    "        cv2.imwrite(frame_path, image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2e007",
   "metadata": {},
   "source": [
    "**Defining a function to clear output folder**  \n",
    "We need to use this whenever user uploads a new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WlUYY50vKXTY",
   "metadata": {
    "id": "WlUYY50vKXTY"
   },
   "outputs": [],
   "source": [
    "def clear_output_folder(output_folder):\n",
    "    if os.path.exists(output_folder):\n",
    "        for file in os.listdir(output_folder):\n",
    "            file_path = os.path.join(output_folder, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                os.rmdir(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359cbec",
   "metadata": {},
   "source": [
    "**Extracting frames from the video and storing in a local output folder**  \n",
    "Here we clear output folder before writing the frames of the new videe so the user's search only applies to the current video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419d2cb-a9f6-4ad8-a219-0fcbe212f4db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1419d2cb-a9f6-4ad8-a219-0fcbe212f4db",
    "outputId": "943ef33e-3750-413c-cd7b-4a0ab22260cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder = 'frames'\n",
    "clear_output_folder(output_folder) #clearing output folder\n",
    "frame_count = extract_frames(video_path, output_folder)\n",
    "print(f'Extracted {frame_count} frames from the video.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f27e6c",
   "metadata": {},
   "source": [
    "**Getting predictions**  \n",
    "Here we pass the frames into InceptionV3 and store its prediction for each frame in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2f587",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSrM0qhqn4eo",
    "outputId": "a5a50377-2aa7-41fb-c5a4-55be2e588ae1"
   },
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "\n",
    "# processing each frame and get predictions\n",
    "for i in tqdm(range(frame_count)):\n",
    "    frame_path = os.path.join(output_folder, f\"frame{i}.jpg\")\n",
    "    predictions = get_predictions(frame_path)\n",
    "    for pred in predictions:\n",
    "        code, object_name, score = pred\n",
    "        predictions_list.append([frame_path, code, object_name, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}\n",
    "for i in tqdm(range(frame_count)):\n",
    "    frame_path = os.path.join(output_folder, f\"frame{i}.jpg\")\n",
    "    predictions = get_predictions(frame_path)\n",
    "    objects = [pred[1] for pred in predictions]\n",
    "    scores = [pred[2] for pred in predictions]\n",
    "    predictions_dict[frame_path] = (objects, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691def81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSrM0qhqn4eo",
    "outputId": "a5a50377-2aa7-41fb-c5a4-55be2e588ae1"
   },
   "source": [
    "Here we store the predictions in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e885e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSrM0qhqn4eo",
    "outputId": "a5a50377-2aa7-41fb-c5a4-55be2e588ae1"
   },
   "outputs": [],
   "source": [
    "object_predictions = pd.DataFrame(predictions_list, columns=['Frame', 'Class Code', 'Object', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89debb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_predictions_summarized = pd.DataFrame([(frame, ', '.join(objs), ', '.join(map(str, scores))) \n",
    "                                   for frame, (objs, scores) in predictions_dict.items()],\n",
    "                                  columns=['Frame', 'Objects', 'Scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc91f7",
   "metadata": {},
   "source": [
    "**Friendly displays of object predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_predictions_summarized.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSrM0qhqn4eo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSrM0qhqn4eo",
    "outputId": "a5a50377-2aa7-41fb-c5a4-55be2e588ae1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "object_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QyJTcIXu1Inp",
   "metadata": {
    "id": "QyJTcIXu1Inp"
   },
   "source": [
    "## Task 5\n",
    "Allow users to type a search query for an object that might be in the uploaded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZvY6TgLhMao5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvY6TgLhMao5",
    "outputId": "51ed38e8-579e-491e-8412-9e955d48f57d"
   },
   "outputs": [],
   "source": [
    "def search_for_object(df, search_query):\n",
    "    search_query = search_query.lower()\n",
    "    results = df[df['Objects'].apply(lambda x: any(search_query in obj.lower() for obj in x.split(', ')))]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451d0f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvY6TgLhMao5",
    "outputId": "51ed38e8-579e-491e-8412-9e955d48f57d"
   },
   "outputs": [],
   "source": [
    "search_query = input(\"Enter the object you want to search for: \").strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cAernEXN1oNg",
   "metadata": {
    "id": "cAernEXN1oNg"
   },
   "source": [
    "## Task 6\n",
    "The application should return and display the frame(s) with the object searched by the user, if it exists. If the object doesn't exist, display an error message: \"Object doesn't exist!!!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6f84e",
   "metadata": {},
   "source": [
    "**Defining a function to display a frame using matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e9ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C5FGq6zszQCh",
    "outputId": "76418385-175a-4005-8131-df8bca5caf7e"
   },
   "outputs": [],
   "source": [
    "def display_frame(frame_path):\n",
    "    img = cv2.imread(frame_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd308e",
   "metadata": {},
   "source": [
    "**Searching for objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db85f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C5FGq6zszQCh",
    "outputId": "76418385-175a-4005-8131-df8bca5caf7e"
   },
   "outputs": [],
   "source": [
    "search_results = search_for_object(object_predictions_summarized, search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03820f",
   "metadata": {},
   "source": [
    "**Displaying them them if they exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C5FGq6zszQCh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C5FGq6zszQCh",
    "outputId": "76418385-175a-4005-8131-df8bca5caf7e"
   },
   "outputs": [],
   "source": [
    "if not search_results.empty:\n",
    "    print(f'Found {search_query} in {len(search_results)} frames.')\n",
    "    print(f'The frames will be displayed below')\n",
    "    for _, row in search_results.iterrows():\n",
    "        frame_path = row['Frame']\n",
    "        display_frame(frame_path)\n",
    "else:\n",
    "    print(\"Object doesn't exist!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ea93e",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdb607",
   "metadata": {},
   "source": [
    "**Bibliography**  \n",
    "[1]Snowflake Inc. 2024. Connect Streamlit to Google Cloud Storage - Streamlit Docs. docs.streamlit.io. Retrieved July 19, 2024 from https://docs.streamlit.io/develop/tutorials/databases/gcs  \n",
    "[2]Keras Team. 2024. Keras documentation: InceptionV3. keras.io. Retrieved July 19, 2024 from https://keras.io/api/applications/inceptionv3/  \n",
    "[3]TensorFlow. 2024. Load video data | TensorFlow Core. TensorFlow. Retrieved July 19, 2024 from https://www.tensorflow.org/tutorials/load_data/video#create_frames_from_each_video_file  \n",
    "[4]TensorFlow. 2024. tf.keras.applications.inception_v3.decode_predictions | TensorFlow v2.16.1. TensorFlow. Retrieved July 19, 2024 from https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/decode_predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
